<!NOTETITLE!>The Basics on Support Vector Machines<!NOTETITLE!>

<!NOTEAUTHOR!>Curtis Thompson<!NOTEAUTHOR!>

<!NOTEDATE!>Friday 29th January 2021<!NOTEDATE!>

<!NOTETOPIC!>Projects and Programming<!NOTETOPIC!>

<!HEADCONTENT!>
		<link rel="stylesheet" type="text/css" href="/stylesheets/main.css" />
    	<link rel="stylesheet" type="text/css" href="/stylesheets/notes.css" />
    	<meta name="author" content="Curtis Thompson" />
    	<meta name="description" content="The support vector machine (SVM) is an incredibly common classical machine learning algorithm that can be used in classification and regression problems. But how does it work?" />
    	<meta name="keywords" content="machine learning, svm, support vector machine, hyperplane, algorithm, data, point, graph, margin" />
<!HEADCONTENT!>

<!BODYCONTENT!>
				<p>The support vector machine (SVM) is an incredibly common classical machine learning algorithm that can be used in classification and regression problems. But how does it work?</p>

				<h2>What is a Support Vector Machine?</h2>
				<p>An SVM is a supervised machine learning algorithm, most commonly used in classification problems.</p>
				<p>In the algorithm, we plot each data point as a point in n-dimensional space (where n is the number of features in the dataset). We then find a hyperplane that differentiates the two classes well, and we can use this to classify data points.</p>
				
				<h2>How Does The Algorithm Work?</h2>
				<p>With the training data points plotted in n-dimensional space, the algorithm finds equations (hyperplanes) that can split the data points into the separate classes. However, there are potentially infinite equations that can do this.</p>
				<div class="captioned-image">
        		    <img alt="SVM Hyperplanes" src="svm2.png" />
        		    <p>Possible hyperplanes to divide the data.</p>
        		</div>
				<p>Therefore, the algorithm will find the equation that maximises the margin, which is the distance between the hyperplane and the closest data point. The hyperplane where the margin of separation is maximised is known as the optimal hyperplane.</p>
				<div class="captioned-image">
        		    <img alt="SVM Optimal Hyperplane" src="svm3.png" />
        		    <p>The optimal hyperplane for the data.</p>
        		</div>
				<p>The best mathematical explanation can probably be found at <a href="https://www.analyticsvidhya.com/blog/2020/10/the-mathematics-behind-svm/" target="_blank">Analytics Vidhya</a>. 
				<p>The SVM algorithm is as simple as that (in basic cases, of course). In real-world data, is in more common for the data to not be linearly separable. However, this can be dealt with by replacing the mathematical dot products with non-linear kernels. This puts the data points into a transformed feature space where the data is now separable.</p>
<!BODYCONTENT!>